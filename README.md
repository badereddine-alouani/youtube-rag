# ğŸ¥ YouTube-RAG: Retrieval-Augmented Generation from YouTube Videos

**YouTube-RAG** is a lightweight app that allows users to ask questions based on the transcript of any YouTube video. It combines modern LLMs and vector databases to create a simple but powerful retrieval-augmented generation (RAG) pipeline.

Built with:
- ğŸ§  [LangChain](https://github.com/langchain-ai/langchain)
- ğŸ” [ChromaDB](https://www.trychroma.com/)
- ğŸ’¬ [DeepSeek LLM](https://openrouter.ai/chat/deepseek) via [OpenRouter](https://openrouter.ai/)
- ğŸ“º [YouTube Transcript API](https://github.com/jdepoix/youtube-transcript-api)
- ğŸŒ [Streamlit](https://streamlit.io/) for the frontend

---

## ğŸš€ Features

- ğŸ”— Enter any YouTube video URL
- ğŸ“ Automatically fetch the transcript (supports multiple languages)
- ğŸ“š Split and embed transcript into a vectorstore (Chroma)
- ğŸ¤– Ask questions about the content using DeepSeek LLM
- â™»ï¸ Persistent or temporary vectorstore support
- ğŸ’¡ Simple Streamlit interface

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/youtube-rag.git
cd youtube-rag

# Create and activate virtual environment (optional)
python -m venv venv
source venv/bin/activate  # on Windows use `venv\Scripts\activate`

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸ› ï¸ Configuration

### ğŸ” OpenRouter API Key (for DeepSeek)
Youâ€™ll need an OpenRouter API key to access DeepSeek or other LLMs.

Create a `.env` file in the project root:

```env
OPENROUTER_API_KEY=your_openrouter_api_key
```

Then make sure your code loads it using `os.getenv("OPENROUTER_API_KEY")`.

---

## ğŸ§  How It Works

1. User enters a YouTube URL and a question in the Streamlit app.
2. The backend:
   - Extracts the video ID and retrieves the transcript via **YouTube Transcript API**
   - Splits and embeds the transcript using **LangChain** with **HuggingFace Embeddings**
   - Stores/fetches embeddings from a **Chroma vectorstore**
3. The userâ€™s question is passed to a **LangChain RAG pipeline** powered by **DeepSeek (via OpenRouter)**
4. The model returns a context-aware answer, grounded in the video transcript.

---

## ğŸ–¥ï¸ Usage

```bash
streamlit run main.py
```

Then open your browser to the URL shown in the terminal (usually http://localhost:8501).

---

## ğŸ“ Project Structure

```
youtube-rag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ interface.py        # Streamlit frontend
â”‚   â”œâ”€â”€ retriever.py        # Vectorstore logic
â”‚   â”œâ”€â”€ rag_chain.py        # LangChain RAG pipeline
â”‚   â””â”€â”€ youtube.py          # Transcript extraction and video ID parsing
â”œâ”€â”€ vectorstores/           # (Ignored) Folder for persisted vectorstores
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“„ .gitignore

Make sure your `.gitignore` includes:

```
/vectorstores/
.env
```

---

## ğŸ§ª Example Prompt

> **YouTube URL:** `https://www.youtube.com/watch?v=dQw4w9WgXcQ`  
> **Question:** "What is the main message of the video?"

---

## ğŸ¤ Contributions

PRs are welcome! Feel free to open issues or suggest improvements.

---

## ğŸ“œ License

MIT License.

---

## ğŸ’¬ Acknowledgments

- [LangChain](https://github.com/langchain-ai/langchain)
- [YouTube Transcript API](https://github.com/jdepoix/youtube-transcript-api)
- [Chroma DB](https://www.trychroma.com/)
- [OpenRouter](https://openrouter.ai/)
- [DeepSeek](https://github.com/deepseek-ai)
- [Streamlit](https://streamlit.io/)
